here the results of the base models to compare with
all used the same config for a given model size, 
    all trained with 256 batchSize, trainProp=0.8, and lr=1.0e-03
    and no data augmentation (to reduce randomness)


base model 1 (medium)
    -> nb parameters: 442_874
    training: 
        Epoch 1, train: (loss: 1.569, accuracy: 44.62%), test: (loss: 1.24, accuracy: 54.93%)
        Epoch 2, train: (loss: 1.021, accuracy: 64.32%), test: (loss: 0.9876, accuracy: 67.33%)
        Epoch 3, train: (loss: 0.8216, accuracy: 71.50%), test: (loss: 0.9175, accuracy: 69.20%)
        Epoch 4, train: (loss: 0.7071, accuracy: 75.54%), test: (loss: 0.8853, accuracy: 70.85%)
        Epoch 5, train: (loss: 0.6154, accuracy: 78.79%), test: (loss: 0.8875, accuracy: 70.88%)
        Epoch 6, train: (loss: 0.53, accuracy: 81.64%), test: (loss: 0.7804, accuracy: 73.58%)
        Epoch 7, train: (loss: 0.455, accuracy: 84.27%), test: (loss: 0.6622, accuracy: 77.61%)
        Epoch 8, train: (loss: 0.3992, accuracy: 86.10%), test: (loss: 0.6336, accuracy: 78.76%)
        Epoch 9, train: (loss: 0.3325, accuracy: 88.59%), test: (loss: 0.6633, accuracy: 78.05%)
        Epoch 10, train: (loss: 0.287, accuracy: 90.08%), test: (loss: 0.7057, accuracy: 78.12%)
    -> best accuracy, train: 90.08 (epoch 10), test: 78.76% (epoch 8)
    time taken:
        all: 100.00% (35.8 sec)
        getBatch: 16.06%, predict+loss: 21.68%, backward: 45.15%, step: 4.40%,
        metrics_base: 1.51%, metrics_moe: 0.00%, evaluate: 9.34%,
        progressBar: 1.29%, other: 0.57%,


base model 2 (small)
    -> nb parameters: 32_362
    training:
        Epoch 1, train: (loss: 1.595, accuracy: 41.17%), test: (loss: 1.305, accuracy: 52.53%)
        Epoch 2, train: (loss: 1.247, accuracy: 55.28%), test: (loss: 1.332, accuracy: 53.84%)
        Epoch 3, train: (loss: 1.118, accuracy: 60.37%), test: (loss: 1.096, accuracy: 61.17%)
        Epoch 4, train: (loss: 1.034, accuracy: 63.66%), test: (loss: 1.116, accuracy: 59.60%)
        Epoch 5, train: (loss: 0.9721, accuracy: 65.68%), test: (loss: 1.001, accuracy: 64.32%)
        Epoch 6, train: (loss: 0.9216, accuracy: 67.51%), test: (loss: 0.9132, accuracy: 67.86%)
        Epoch 7, train: (loss: 0.8857, accuracy: 68.94%), test: (loss: 0.944, accuracy: 66.93%)
        Epoch 8, train: (loss: 0.8454, accuracy: 70.44%), test: (loss: 0.8778, accuracy: 69.34%)
        Epoch 9, train: (loss: 0.8224, accuracy: 71.48%), test: (loss: 0.8506, accuracy: 70.30%)
        Epoch 10, train: (loss: 0.7926, accuracy: 72.46%), test: (loss: 0.8466, accuracy: 70.36%)
        Epoch 11, train: (loss: 0.7682, accuracy: 73.22%), test: (loss: 0.8253, accuracy: 71.13%)
        Epoch 12, train: (loss: 0.7526, accuracy: 73.70%), test: (loss: 0.8736, accuracy: 70.16%)
        Epoch 13, train: (loss: 0.7298, accuracy: 74.53%), test: (loss: 0.9719, accuracy: 66.26%)
        Epoch 14, train: (loss: 0.7195, accuracy: 75.06%), test: (loss: 0.8503, accuracy: 70.20%)
        Epoch 15, train: (loss: 0.6996, accuracy: 75.48%), test: (loss: 0.814, accuracy: 71.91%)
        Epoch 16, train: (loss: 0.6902, accuracy: 75.64%), test: (loss: 0.7783, accuracy: 72.93%)
        Epoch 17, train: (loss: 0.6677, accuracy: 76.48%), test: (loss: 0.8725, accuracy: 69.95%)
        Epoch 18, train: (loss: 0.6598, accuracy: 76.98%), test: (loss: 0.7957, accuracy: 72.25%)
        Epoch 19, train: (loss: 0.6529, accuracy: 77.04%), test: (loss: 0.7911, accuracy: 72.63%)
        Epoch 20, train: (loss: 0.6424, accuracy: 77.48%), test: (loss: 0.9117, accuracy: 69.11%)
        Epoch 21, train: (loss: 0.6254, accuracy: 78.12%), test: (loss: 0.8482, accuracy: 70.85%)
        Epoch 22, train: (loss: 0.6234, accuracy: 78.26%), test: (loss: 0.8183, accuracy: 72.22%)
        Epoch 23, train: (loss: 0.61, accuracy: 78.48%), test: (loss: 0.7866, accuracy: 72.92%)
        Epoch 24, train: (loss: 0.6038, accuracy: 78.95%), test: (loss: 0.7583, accuracy: 73.61%)
        Epoch 25, train: (loss: 0.5991, accuracy: 79.08%), test: (loss: 0.8053, accuracy: 72.73%)
        Epoch 26, train: (loss: 0.589, accuracy: 79.33%), test: (loss: 0.7848, accuracy: 72.80%)
        Epoch 27, train: (loss: 0.5798, accuracy: 79.60%), test: (loss: 0.7434, accuracy: 74.06%)
        Epoch 28, train: (loss: 0.573, accuracy: 79.91%), test: (loss: 0.7653, accuracy: 73.94%)
        Epoch 29, train: (loss: 0.566, accuracy: 79.95%), test: (loss: 0.7673, accuracy: 73.77%)
        Epoch 30, train: (loss: 0.5533, accuracy: 80.38%), test: (loss: 0.8439, accuracy: 71.09%)
    -> best accuracy, train: 80.38% (epoch 30), test: 74.80% (epoch 27)
    time taken:
        all: 100.00% (52.5 sec)
        getBatch: 12.54%, predict+loss: 24.10%, backward: 39.75%, step: 9.00%,
        metrics_base: 3.17%, metrics_moe: 0.01%, evaluate: 8.87%,
        progressBar: 1.51%, other: 1.06%


base model 3 (large)
    -> nb parameters: 1_928_138
    training:
        Epoch 1, train: (loss: 1.819, accuracy: 38.63%), test: (loss: 1.556, accuracy: 45.19%)
        Epoch 2, train: (loss: 1.202, accuracy: 57.73%), test: (loss: 1.324, accuracy: 57.62%)
        Epoch 3, train: (loss: 0.9522, accuracy: 67.08%), test: (loss: 1.047, accuracy: 64.44%)
        Epoch 4, train: (loss: 0.8125, accuracy: 71.95%), test: (loss: 0.8414, accuracy: 71.96%)
        Epoch 5, train: (loss: 0.6799, accuracy: 76.45%), test: (loss: 0.8053, accuracy: 72.44%)
        Epoch 6, train: (loss: 0.585, accuracy: 79.80%), test: (loss: 0.883, accuracy: 71.07%)
        Epoch 7, train: (loss: 0.5072, accuracy: 82.44%), test: (loss: 0.6945, accuracy: 77.26%)
        Epoch 8, train: (loss: 0.4488, accuracy: 84.45%), test: (loss: 0.6427, accuracy: 79.16%)
        Epoch 9, train: (loss: 0.3893, accuracy: 86.38%), test: (loss: 0.6532, accuracy: 78.88%)
        Epoch 10, train: (loss: 0.3288, accuracy: 88.46%), test: (loss: 0.621, accuracy: 80.38%)
    -> best accuracy, train: 88.46% (epoch 10), test: 80.38% (epoch 10)
    time taken:
        all: 100.00% (77.0 sec)
        getBatch: 7.60%, predict+loss: 23.26%, backward: 57.53%, step: 2.02%,
        metrics_base: 0.70%, metrics_moe: 0.00%, evaluate: 7.48%, 
        progressBar: 1.14%, other: 0.27%

---------------------------------------------------------------------------


here the results of the MOE models to compare with

moe model 1 (gating:small, experts: 12 x small)
    -> nb parameters: total(422_244), gating(33_900), experts(12 x 32_362)
    training:
        Epoch 1, train: (loss: 0.7861, accuracy: 43.06%), test: (loss: 0.7366, accuracy: 46.68%)
        Epoch 2, train: (loss: 0.6133, accuracy: 56.13%), test: (loss: 0.6531, accuracy: 54.17%)
        Epoch 3, train: (loss: 0.5433, accuracy: 61.71%), test: (loss: 0.5406, accuracy: 61.21%)
        Epoch 4, train: (loss: 0.4912, accuracy: 65.22%), test: (loss: 0.5062, accuracy: 63.73%)
        Epoch 5, train: (loss: 0.4652, accuracy: 67.34%), test: (loss: 0.4622, accuracy: 67.38%)
        Epoch 6, train: (loss: 0.4402, accuracy: 69.37%), test: (loss: 0.5213, accuracy: 63.55%)
        Epoch 7, train: (loss: 0.4249, accuracy: 70.45%), test: (loss: 0.5687, accuracy: 61.14%)
        Epoch 8, train: (loss: 0.4077, accuracy: 71.79%), test: (loss: 0.4488, accuracy: 67.94%)
        Epoch 9, train: (loss: 0.3897, accuracy: 72.93%), test: (loss: 0.4209, accuracy: 70.84%)
        Epoch 10, train: (loss: 0.3802, accuracy: 73.48%), test: (loss: 0.4156, accuracy: 70.83%)
        Epoch 11, train: (loss: 0.3707, accuracy: 74.20%), test: (loss: 0.4102, accuracy: 71.44%)
        Epoch 12, train: (loss: 0.362, accuracy: 74.84%), test: (loss: 0.3961, accuracy: 72.00%)
        Epoch 13, train: (loss: 0.354, accuracy: 75.41%), test: (loss: 0.409, accuracy: 70.95%)
        Epoch 14, train: (loss: 0.3453, accuracy: 76.10%), test: (loss: 0.3974, accuracy: 72.14%)
        Epoch 15, train: (loss: 0.3395, accuracy: 76.41%), test: (loss: 0.3724, accuracy: 73.83%)
        Epoch 16, train: (loss: 0.3286, accuracy: 77.07%), test: (loss: 0.3802, accuracy: 73.38%)
        Epoch 17, train: (loss: 0.3248, accuracy: 77.36%), test: (loss: 0.3949, accuracy: 72.53%)
        Epoch 18, train: (loss: 0.3204, accuracy: 77.72%), test: (loss: 0.4838, accuracy: 67.10%)
        Epoch 19, train: (loss: 0.315, accuracy: 77.98%), test: (loss: 0.3735, accuracy: 73.49%)
        Epoch 20, train: (loss: 0.3069, accuracy: 78.59%), test: (loss: 0.3814, accuracy: 73.32%)
        Epoch 21, train: (loss: 0.3036, accuracy: 78.78%), test: (loss: 0.4382, accuracy: 69.85%)
        Epoch 22, train: (loss: 0.2982, accuracy: 79.22%), test: (loss: 0.3744, accuracy: 74.22%)
        Epoch 23, train: (loss: 0.2936, accuracy: 79.40%), test: (loss: 0.4027, accuracy: 71.97%)
        Epoch 24, train: (loss: 0.2911, accuracy: 79.48%), test: (loss: 0.3833, accuracy: 73.36%)
        Epoch 25, train: (loss: 0.2847, accuracy: 79.94%), test: (loss: 0.4338, accuracy: 70.89%)
        Epoch 26, train: (loss: 0.2811, accuracy: 80.38%), test: (loss: 0.3878, accuracy: 73.51%)
        Epoch 27, train: (loss: 0.2807, accuracy: 80.09%), test: (loss: 0.3612, accuracy: 75.27%)
        Epoch 28, train: (loss: 0.2766, accuracy: 80.33%), test: (loss: 0.3785, accuracy: 73.78%)
        Epoch 29, train: (loss: 0.2707, accuracy: 80.67%), test: (loss: 0.3682, accuracy: 74.73%)
        Epoch 30, train: (loss: 0.2706, accuracy: 80.93%), test: (loss: 0.4176, accuracy: 72.10%)
    -> best accuracy, train: 80.93% (epoch 30), test: 75.27% (epoch 27)
    time taken:
        all: 100.00% (459.0 sec)
        getBatch: 1.82%, predict+loss: 33.40%, backward: 53.09%, step: 2.61%,
        metrics_base: 0.40%, metrics_moe: 0.00%, evaluate: 7.40%,
        progressBar: 1.01%, other: 0.27%
    experts gates (tests):
        mean: [0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] (std: 0.276)
        std: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] (mean: 0.0)
        perClassPred: 
          [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
           [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]
           [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
           [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
           [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
           [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
           [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
           [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
           [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
           [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
           [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
           [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]


moe model 2 (gating:small, experts: 6 x small)
    -> nb parameters: total(223_458), gating(29_286), experts(6 x 32_362)
    training:
        Epoch 1, train: (loss: 0.8018, accuracy: 42.03%), test: (loss: 0.8007, accuracy: 44.27%)
        Epoch 2, train: (loss: 0.6265, accuracy: 55.35%), test: (loss: 0.603, accuracy: 57.72%)
        Epoch 3, train: (loss: 0.5546, accuracy: 60.91%), test: (loss: 0.8758, accuracy: 44.54%)
        Epoch 4, train: (loss: 0.5059, accuracy: 64.33%), test: (loss: 0.6685, accuracy: 54.49%)
        Epoch 5, train: (loss: 0.4738, accuracy: 66.86%), test: (loss: 0.5611, accuracy: 60.90%)
        Epoch 6, train: (loss: 0.4477, accuracy: 68.69%), test: (loss: 0.4682, accuracy: 66.75%)
        Epoch 7, train: (loss: 0.4263, accuracy: 70.21%), test: (loss: 0.4743, accuracy: 66.34%)
        Epoch 8, train: (loss: 0.4117, accuracy: 71.14%), test: (loss: 0.4606, accuracy: 67.84%)
        Epoch 9, train: (loss: 0.3995, accuracy: 72.16%), test: (loss: 0.4429, accuracy: 68.77%)
        Epoch 10, train: (loss: 0.386, accuracy: 73.29%), test: (loss: 0.4096, accuracy: 70.96%)
        Epoch 11, train: (loss: 0.3784, accuracy: 73.64%), test: (loss: 0.3899, accuracy: 72.41%)
        Epoch 12, train: (loss: 0.3652, accuracy: 74.53%), test: (loss: 0.4087, accuracy: 71.12%)
        Epoch 13, train: (loss: 0.3584, accuracy: 74.91%), test: (loss: 0.4439, accuracy: 69.23%)
        Epoch 14, train: (loss: 0.3508, accuracy: 75.61%), test: (loss: 0.4558, accuracy: 68.47%)
        Epoch 15, train: (loss: 0.3424, accuracy: 76.07%), test: (loss: 0.3974, accuracy: 72.46%)
        Epoch 16, train: (loss: 0.3366, accuracy: 76.37%), test: (loss: 0.4127, accuracy: 70.99%)
        Epoch 17, train: (loss: 0.3299, accuracy: 76.91%), test: (loss: 0.4773, accuracy: 67.97%)
        Epoch 18, train: (loss: 0.3239, accuracy: 77.32%), test: (loss: 0.4015, accuracy: 71.99%)
        Epoch 19, train: (loss: 0.3182, accuracy: 77.77%), test: (loss: 0.3907, accuracy: 72.95%)
        Epoch 20, train: (loss: 0.3142, accuracy: 78.13%), test: (loss: 0.3715, accuracy: 74.13%)
        Epoch 21, train: (loss: 0.3077, accuracy: 78.46%), test: (loss: 0.3855, accuracy: 73.01%)
        Epoch 22, train: (loss: 0.3027, accuracy: 78.83%), test: (loss: 0.3555, accuracy: 75.45%)
        Epoch 23, train: (loss: 0.2993, accuracy: 79.04%), test: (loss: 0.367, accuracy: 74.55%)
        Epoch 24, train: (loss: 0.2926, accuracy: 79.23%), test: (loss: 0.3931, accuracy: 72.95%)
        Epoch 25, train: (loss: 0.2898, accuracy: 79.75%), test: (loss: 0.4025, accuracy: 72.17%)
        Epoch 26, train: (loss: 0.2872, accuracy: 79.67%), test: (loss: 0.4282, accuracy: 70.74%)
        Epoch 27, train: (loss: 0.2836, accuracy: 79.94%), test: (loss: 0.3538, accuracy: 75.59%)
        Epoch 28, train: (loss: 0.2815, accuracy: 80.26%), test: (loss: 0.3691, accuracy: 74.68%)
        Epoch 29, train: (loss: 0.2789, accuracy: 80.43%), test: (loss: 0.4126, accuracy: 71.66%)
        Epoch 30, train: (loss: 0.273, accuracy: 80.78%), test: (loss: 0.3883, accuracy: 73.62%)
    -> best accuracy, train: 80.78% (epoch 30), test: 75.59% (epoch 27)
    time taken:
        all: 100.00% (260.7 sec)
        getBatch: 3.05%, predict+loss: 32.23%, backward: 52.08%, step: 2.97%,
        metrics_base: 0.67%, metrics_moe: 0.00%, evaluate: 7.68%,
        progressBar: 0.97%, other: 0.35%
    experts gates (tests):
        mean: [0. 0. 0. 0. 0. 1.] (std: 0.373)
        std: [0. 0. 0. 0. 0. 0.] (mean: 0.0)
        perClassPred: 
          [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
           [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
           [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
           [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
           [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
           [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]]
        

moe model 3 (gating:medium, experts: 6 x small)
    -> nb parameters: total(620_658), gating(426_486), experts(6 x 32_362)
    training:
        Epoch 1, train: (loss: 0.7926, accuracy: 42.54%), test: (loss: 0.7023, accuracy: 48.97%)
        Epoch 2, train: (loss: 0.6195, accuracy: 56.24%), test: (loss: 0.6478, accuracy: 54.20%)
        Epoch 3, train: (loss: 0.5432, accuracy: 61.93%), test: (loss: 0.5272, accuracy: 62.69%)
        Epoch 4, train: (loss: 0.4928, accuracy: 65.72%), test: (loss: 0.508, accuracy: 63.83%)
        Epoch 5, train: (loss: 0.4611, accuracy: 68.00%), test: (loss: 0.5029, accuracy: 65.14%)
        Epoch 6, train: (loss: 0.4378, accuracy: 69.64%), test: (loss: 0.4906, accuracy: 67.11%)
        Epoch 7, train: (loss: 0.414, accuracy: 71.19%), test: (loss: 0.4984, accuracy: 64.88%)
        Epoch 8, train: (loss: 0.3956, accuracy: 72.53%), test: (loss: 0.526, accuracy: 63.36%)
        Epoch 9, train: (loss: 0.3808, accuracy: 73.69%), test: (loss: 0.4193, accuracy: 70.61%)
        Epoch 10, train: (loss: 0.3669, accuracy: 74.51%), test: (loss: 0.4302, accuracy: 70.21%)
        Epoch 11, train: (loss: 0.3545, accuracy: 75.54%), test: (loss: 0.4366, accuracy: 70.01%)
        Epoch 12, train: (loss: 0.3447, accuracy: 75.94%), test: (loss: 0.4165, accuracy: 71.38%)
        Epoch 13, train: (loss: 0.3335, accuracy: 76.85%), test: (loss: 0.5114, accuracy: 65.59%)
        Epoch 14, train: (loss: 0.3252, accuracy: 77.45%), test: (loss: 0.4556, accuracy: 70.02%)
        Epoch 15, train: (loss: 0.311, accuracy: 78.33%), test: (loss: 0.4954, accuracy: 67.74%)
        Epoch 16, train: (loss: 0.3062, accuracy: 78.61%), test: (loss: 0.3949, accuracy: 73.18%)
        Epoch 17, train: (loss: 0.301, accuracy: 79.07%), test: (loss: 0.4444, accuracy: 69.67%)
        Epoch 18, train: (loss: 0.288, accuracy: 79.78%), test: (loss: 0.4559, accuracy: 70.03%)
        Epoch 19, train: (loss: 0.2848, accuracy: 80.01%), test: (loss: 0.4438, accuracy: 71.08%)
        Epoch 20, train: (loss: 0.2763, accuracy: 80.84%), test: (loss: 0.3932, accuracy: 74.01%)
        Epoch 21, train: (loss: 0.2712, accuracy: 80.97%), test: (loss: 0.3954, accuracy: 73.60%)
        Epoch 22, train: (loss: 0.2653, accuracy: 81.49%), test: (loss: 0.3856, accuracy: 74.11%)
        Epoch 23, train: (loss: 0.2623, accuracy: 81.47%), test: (loss: 0.3813, accuracy: 74.25%)
        Epoch 24, train: (loss: 0.2527, accuracy: 82.25%), test: (loss: 0.4141, accuracy: 71.99%)
        Epoch 25, train: (loss: 0.25, accuracy: 82.56%), test: (loss: 0.4135, accuracy: 73.20%)
        Epoch 26, train: (loss: 0.2458, accuracy: 82.84%), test: (loss: 0.3915, accuracy: 74.57%)
        Epoch 27, train: (loss: 0.2409, accuracy: 82.93%), test: (loss: 0.4094, accuracy: 73.35%)
        Epoch 28, train: (loss: 0.2354, accuracy: 83.46%), test: (loss: 0.4088, accuracy: 73.26%)
        Epoch 29, train: (loss: 0.2299, accuracy: 83.64%), test: (loss: 0.447, accuracy: 71.41%)
        Epoch 30, train: (loss: 0.2248, accuracy: 84.15%), test: (loss: 0.393, accuracy: 74.14%)
    -> best accuracy, train: 84.15% (epoch 30), test: 74.57% (epoch 26)
    time taken:
        all: 100.00% (422.6 sec)
        getBatch: 2.79%, predict+loss: 32.11%, backward: 52.78%, step: 2.82%, 
        metrics_base: 0.60%, metrics_moe: 0.00%, evaluate: 7.57%,
        progressBar: 1.01%, other: 0.33%


moe model 4 (gating:small, experts: 4 x medium)
    -> nb parameters: total(1_799_244), gating(27_748), experts(4 x 442_874)
    training:
        Epoch 1, train: (loss: 0.7179, accuracy: 50.04%), test: (loss: 0.626, accuracy: 55.17%)
        Epoch 2, train: (loss: 0.4606, accuracy: 67.72%), test: (loss: 0.4563, accuracy: 68.36%)
        Epoch 3, train: (loss: 0.3763, accuracy: 73.92%), test: (loss: 0.4029, accuracy: 72.27%)
        Epoch 4, train: (loss: 0.3136, accuracy: 78.24%), test: (loss: 0.4948, accuracy: 68.85%)
        Epoch 5, train: (loss: 0.2744, accuracy: 81.02%), test: (loss: 0.3817, accuracy: 74.48%)
        Epoch 6, train: (loss: 0.2387, accuracy: 83.41%), test: (loss: 0.3465, accuracy: 77.55%)
        Epoch 7, train: (loss: 0.201, accuracy: 85.95%), test: (loss: 0.3181, accuracy: 78.88%)
        Epoch 8, train: (loss: 0.1755, accuracy: 87.79%), test: (loss: 0.3376, accuracy: 78.27%)
        Epoch 9, train: (loss: 0.1543, accuracy: 89.17%), test: (loss: 0.3079, accuracy: 79.92%)
        Epoch 10, train: (loss: 0.1273, accuracy: 91.17%), test: (loss: 0.331, accuracy: 79.29%)
    -> best accuracy, train: 91.17% (epoch 10), test: 79.92% (epoch 9)
    time taken:
        all: 100.00% (117.9 sec)
        getBatch: 2.31%, predict+loss: 29.73%, backward: 56.30%, step: 2.33%, 
        metrics_base: 0.49%, metrics_moe: 0.00%, evaluate: 7.20%,
        progressBar: 1.36%, other: 0.27%
    experts gates (tests):
        mean: [1. 0. 0. 0.] (std: 0.433)
        std: [0.001 0.    0.    0.   ] (mean: 0.0)
        perClassPred: 
          [[1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]
           [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
           [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
           [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]


moe model 5 (gating:medium, experts: 4 x medium)
    -> nb parameters: total(2_189_788), gating(418_292), experts(4 x 442_874)
    training:
        Epoch 1, train: (loss: 0.7745, accuracy: 45.19%), test: (loss: 0.7071, accuracy: 50.07%)
        Epoch 2, train: (loss: 0.4958, accuracy: 65.20%), test: (loss: 0.4805, accuracy: 66.28%)
        Epoch 3, train: (loss: 0.4042, accuracy: 71.89%), test: (loss: 0.4289, accuracy: 70.23%)
        Epoch 4, train: (loss: 0.3369, accuracy: 76.57%), test: (loss: 0.4152, accuracy: 72.12%)
        Epoch 5, train: (loss: 0.2966, accuracy: 79.22%), test: (loss: 0.3374, accuracy: 76.70%)
        Epoch 6, train: (loss: 0.2571, accuracy: 82.00%), test: (loss: 0.3537, accuracy: 76.84%)
        Epoch 7, train: (loss: 0.2216, accuracy: 84.47%), test: (loss: 0.3144, accuracy: 78.57%)
        Epoch 8, train: (loss: 0.1886, accuracy: 86.83%), test: (loss: 0.3584, accuracy: 76.92%)
        Epoch 9, train: (loss: 0.1633, accuracy: 88.70%), test: (loss: 0.3333, accuracy: 78.50%)
        Epoch 10, train: (loss: 0.1444, accuracy: 89.89%), test: (loss: 0.3364, accuracy: 79.33%)
    -> best accuracy, train: 89.89% (epoch 10), test: 79.33% (epoch 10)
    time taken:
        all: 100.00% (133.0 sec)
        getBatch: 2.14%, predict+loss: 29.54%, backward: 57.13%, step: 2.19%, 
        metrics_base: 0.44%, metrics_moe: 0.00%, evaluate: 7.00%,
        progressBar: 1.31%, other: 0.25%
    experts gates (tests):
        mean: [0. 0. 0. 1.] (std: 0.433)
        std: [0. 0. 0. 0.] (mean: 0.0)
        perClassPred: 
          [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
           [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
           [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
           [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]]


moe model 6 (gating:small, experts: 4 x large)
    -> nb parameters: total(7_740_300), gating(27_748), experts(4 x 1_928_138)
    training:
        Epoch 1, train: (loss: 1.016, accuracy: 32.63%), test: (loss: 0.8127, accuracy: 40.04%)
        Epoch 2, train: (loss: 0.7033, accuracy: 50.10%), test: (loss: 0.6466, accuracy: 54.52%)
        Epoch 3, train: (loss: 0.5711, accuracy: 59.89%), test: (loss: 0.5408, accuracy: 61.45%)
        Epoch 4, train: (loss: 0.4826, accuracy: 66.73%), test: (loss: 0.5595, accuracy: 60.30%)
        Epoch 5, train: (loss: 0.4138, accuracy: 71.67%), test: (loss: 0.5052, accuracy: 64.80%)
        Epoch 6, train: (loss: 0.3682, accuracy: 74.90%), test: (loss: 0.3804, accuracy: 73.97%)
        Epoch 7, train: (loss: 0.3205, accuracy: 78.16%), test: (loss: 0.3781, accuracy: 73.51%)
        Epoch 8, train: (loss: 0.2859, accuracy: 80.56%), test: (loss: 0.3569, accuracy: 76.25%)
        Epoch 9, train: (loss: 0.2547, accuracy: 82.53%), test: (loss: 0.3289, accuracy: 77.88%)
        Epoch 10, train: (loss: 0.2287, accuracy: 84.49%), test: (loss: 0.3561, accuracy: 76.28%)
    -> best accuracy, train: 84.49% (epoch 10), test: 77.88% (epoch 9)
    time taken:
        all: 100.00% (305.0 sec)
        getBatch: 0.99%, predict+loss: 26.68%, backward: 63.67%, step: 1.35%,
        metrics_base: 0.20%, metrics_moe: 0.00%, evaluate: 6.44%,
        progressBar: 0.55%, other: 0.11%


moe model 7 (gating:medium, experts: 4 x large)
    -> nb parameters: total(8_130_844), gating(418_292), experts(4 x 1_928_138)
    training:
        Epoch 1, train: (loss: 0.9167, accuracy: 39.36%), test: (loss: 0.7779, accuracy: 47.07%)
        Epoch 2, train: (loss: 0.5944, accuracy: 58.50%), test: (loss: 0.5628, accuracy: 61.23%)
        Epoch 3, train: (loss: 0.4719, accuracy: 67.40%), test: (loss: 0.461, accuracy: 68.41%)
        Epoch 4, train: (loss: 0.3922, accuracy: 72.85%), test: (loss: 0.5723, accuracy: 62.99%)
        Epoch 5, train: (loss: 0.3348, accuracy: 76.98%), test: (loss: 0.3872, accuracy: 74.04%)
        Epoch 6, train: (loss: 0.2843, accuracy: 80.40%), test: (loss: 0.3719, accuracy: 75.51%)
        Epoch 7, train: (loss: 0.2541, accuracy: 82.39%), test: (loss: 0.4299, accuracy: 72.98%)
        Epoch 8, train: (loss: 0.2191, accuracy: 84.82%), test: (loss: 0.3576, accuracy: 76.90%)
        Epoch 9, train: (loss: 0.1848, accuracy: 87.22%), test: (loss: 0.3088, accuracy: 79.83%)
        Epoch 10, train: (loss: 0.153, accuracy: 89.19%), test: (loss: 0.3395, accuracy: 78.81%)
    -> best accuracy, train: 89.19% (epoch 10), test: 79.83% (epoch 9)
    time taken:
        all: 100.00% (319.1 sec)
        getBatch: 0.96%, predict+loss: 26.64%, backward: 63.87%, step: 1.38%, 
        metrics_base: 0.20%, metrics_moe: 0.00%, evaluate: 6.32%,
        progressBar: 0.52%, other: 0.11%



---------------------------------------------------------------------------


here the results of the MOE (lossV2) models to compare with

moe2 model 1 (gating:small, experts: 6 x small)
    -> nb parameters: total(223_458), gating(29_286), experts(6 x 32_362)
    training:
        Epoch 1, train: (loss: 0.8044, accuracy: 43.81%), test: (loss: 0.7107, accuracy: 51.13%)
        Epoch 2, train: (loss: 0.638, accuracy: 56.65%), test: (loss: 0.6354, accuracy: 57.04%)
        Epoch 3, train: (loss: 0.5704, accuracy: 61.55%), test: (loss: 0.5873, accuracy: 60.25%)
        Epoch 4, train: (loss: 0.5188, accuracy: 65.37%), test: (loss: 0.5412, accuracy: 63.35%)
        Epoch 5, train: (loss: 0.4811, accuracy: 67.79%), test: (loss: 0.5784, accuracy: 61.96%)
        Epoch 6, train: (loss: 0.4507, accuracy: 69.82%), test: (loss: 0.4994, accuracy: 66.80%)
        Epoch 7, train: (loss: 0.4218, accuracy: 71.80%), test: (loss: 0.4808, accuracy: 68.12%)
        Epoch 8, train: (loss: 0.4017, accuracy: 73.17%), test: (loss: 0.5011, accuracy: 66.11%)
        Epoch 9, train: (loss: 0.3828, accuracy: 74.42%), test: (loss: 0.4779, accuracy: 68.53%)
        Epoch 10, train: (loss: 0.3643, accuracy: 75.49%), test: (loss: 0.544, accuracy: 65.48%)
        Epoch 11, train: (loss: 0.344, accuracy: 76.89%), test: (loss: 0.4882, accuracy: 68.01%)
        Epoch 12, train: (loss: 0.3299, accuracy: 77.82%), test: (loss: 0.4752, accuracy: 69.00%)
        Epoch 13, train: (loss: 0.3118, accuracy: 79.09%), test: (loss: 0.4612, accuracy: 70.21%)
        Epoch 14, train: (loss: 0.2959, accuracy: 80.27%), test: (loss: 0.4683, accuracy: 69.83%)
        Epoch 15, train: (loss: 0.283, accuracy: 81.08%), test: (loss: 0.4666, accuracy: 69.84%)
        Epoch 16, train: (loss: 0.2741, accuracy: 81.88%), test: (loss: 0.479, accuracy: 69.92%)
        Epoch 17, train: (loss: 0.2617, accuracy: 82.56%), test: (loss: 0.5215, accuracy: 67.67%)
        Epoch 18, train: (loss: 0.2451, accuracy: 83.69%), test: (loss: 0.5069, accuracy: 69.18%)
        Epoch 19, train: (loss: 0.2372, accuracy: 84.13%), test: (loss: 0.4688, accuracy: 71.11%)
        Epoch 20, train: (loss: 0.2324, accuracy: 84.42%), test: (loss: 0.4895, accuracy: 71.13%)
        Epoch 21, train: (loss: 0.216, accuracy: 85.72%), test: (loss: 0.4732, accuracy: 71.26%)
        Epoch 22, train: (loss: 0.2128, accuracy: 85.86%), test: (loss: 0.4813, accuracy: 71.22%)
        Epoch 23, train: (loss: 0.2044, accuracy: 86.28%), test: (loss: 0.516, accuracy: 69.58%)
        Epoch 24, train: (loss: 0.1932, accuracy: 87.27%), test: (loss: 0.5004, accuracy: 70.46%)
        Epoch 25, train: (loss: 0.1866, accuracy: 87.41%), test: (loss: 0.5005, accuracy: 70.77%)
        Epoch 26, train: (loss: 0.1778, accuracy: 88.29%), test: (loss: 0.5196, accuracy: 70.04%)
        Epoch 27, train: (loss: 0.1739, accuracy: 88.37%), test: (loss: 0.5262, accuracy: 69.68%)
        Epoch 28, train: (loss: 0.1664, accuracy: 89.06%), test: (loss: 0.5371, accuracy: 70.05%)
        Epoch 29, train: (loss: 0.1631, accuracy: 89.22%), test: (loss: 0.5119, accuracy: 70.73%)
        Epoch 30, train: (loss: 0.1546, accuracy: 89.80%), test: (loss: 0.5355, accuracy: 70.14%)
    -> best accuracy, train: 89.80% (epoch 30), test: 71.26% (epoch 21)
    time taken:
        all: 100.00% (265.3 sec)
        getBatch: 2.76%, predict+loss: 31.79%, backward: 51.02%, step: 2.76%, 
        metrics_base: 0.62%, metrics_moe: 1.90%, evaluate: 7.96%, 
        progressBar: 0.86%, other: 0.33%
    experts gates (tests):
        mean: [0.237 0.142 0.176 0.201 0.086 0.159] (std: 0.047)
        std: [0.154 0.11  0.188 0.245 0.093 0.083] (mean: 0.146)
        perClassPred: 
          [[0.05 0.08 0.24 0.42 0.24 0.38 0.21 0.53 0.05 0.18]
           [0.05 0.34 0.15 0.18 0.03 0.33 0.02 0.1  0.08 0.11]
           [0.38 0.34 0.05 0.02 0.03 0.   0.   0.06 0.53 0.32]
           [0.02 0.03 0.3  0.07 0.65 0.12 0.68 0.18 0.   0.01]
           [0.31 0.06 0.08 0.06 0.01 0.06 0.   0.01 0.22 0.04]
           [0.19 0.15 0.18 0.25 0.05 0.1  0.09 0.12 0.12 0.34]]
 

moe2 model 2 (gating:small, experts: 4 x medium)
    -> nb parameters: total(1_799_244), gating(27_748), experts(4 x 442_874)
    training:
        Epoch 1, train: (loss: 0.7759, accuracy: 48.50%), test: (loss: 0.6415, accuracy: 58.40%)
        Epoch 2, train: (loss: 0.5279, accuracy: 66.70%), test: (loss: 0.5851, accuracy: 63.53%)
        Epoch 3, train: (loss: 0.4311, accuracy: 73.57%), test: (loss: 0.5122, accuracy: 68.75%)
        Epoch 4, train: (loss: 0.3745, accuracy: 77.09%), test: (loss: 0.4151, accuracy: 76.28%)
        Epoch 5, train: (loss: 0.3255, accuracy: 80.23%), test: (loss: 0.483, accuracy: 71.57%)
        Epoch 6, train: (loss: 0.2899, accuracy: 82.73%), test: (loss: 0.4529, accuracy: 73.38%)
        Epoch 7, train: (loss: 0.2553, accuracy: 84.65%), test: (loss: 0.4024, accuracy: 75.99%)
        Epoch 8, train: (loss: 0.2204, accuracy: 86.74%), test: (loss: 0.4017, accuracy: 76.06%)
        Epoch 9, train: (loss: 0.1899, accuracy: 88.33%), test: (loss: 0.3841, accuracy: 77.60%)
        Epoch 10, train: (loss: 0.1622, accuracy: 90.21%), test: (loss: 0.3954, accuracy: 76.44%)
    -> best accuracy, train: 90.21% (epoch 10), test: 77.60% (epoch 9)
    time taken:
        all: 100.00% (123.5 sec)
        getBatch: 2.21%, predict+loss: 29.27%, backward: 55.52%, step: 2.18%, 
        metrics_base: 0.46%, metrics_moe: 1.43%, evaluate: 7.47%, 
        progressBar: 1.21%, other: 0.26%
    experts gates (tests):
        mean: [0.244 0.274 0.169 0.314] (std: 0.053)
        std: [0.09  0.123 0.13  0.134] (mean: 0.119)
        perClassPred: 
          [[0.09 0.41 0.23 0.24 0.29 0.23 0.36 0.16 0.2  0.29]
           [0.54 0.16 0.28 0.31 0.25 0.18 0.17 0.33 0.34 0.08]
           [0.02 0.04 0.22 0.26 0.28 0.36 0.32 0.23 0.02 0.02]
           [0.35 0.38 0.26 0.19 0.18 0.22 0.14 0.28 0.44 0.61]]


moe2 model 3 (gating:small, experts: 12 x small)
    -> nb parameters: total(422_244), gating(33_900), experts(12 x 32_362)
    training:
        Epoch 1, train: (loss: 0.8035, accuracy: 44.25%), test: (loss: 0.6894, accuracy: 51.75%), lr: 1.0000e-03
        Epoch 2, train: (loss: 0.6337, accuracy: 57.25%), test: (loss: 0.6427, accuracy: 56.63%), lr: 1.0000e-03
        Epoch 3, train: (loss: 0.563, accuracy: 62.26%), test: (loss: 0.6331, accuracy: 58.54%), lr: 1.0000e-03
        Epoch 4, train: (loss: 0.5206, accuracy: 65.77%), test: (loss: 0.6002, accuracy: 61.71%), lr: 1.0000e-03
        Epoch 5, train: (loss: 0.4813, accuracy: 68.27%), test: (loss: 0.6204, accuracy: 61.27%), lr: 1.0000e-03
        Epoch 6, train: (loss: 0.455, accuracy: 70.10%), test: (loss: 0.6005, accuracy: 60.14%), lr: 1.0000e-03
        Epoch 7, train: (loss: 0.4286, accuracy: 71.94%), test: (loss: 0.5222, accuracy: 66.04%), lr: 1.0000e-03
        Epoch 8, train: (loss: 0.4077, accuracy: 73.28%), test: (loss: 0.4682, accuracy: 69.83%), lr: 1.0000e-03
        Epoch 9, train: (loss: 0.3865, accuracy: 74.80%), test: (loss: 0.4741, accuracy: 68.90%), lr: 1.0000e-03
        Epoch 10, train: (loss: 0.3669, accuracy: 76.02%), test: (loss: 0.4607, accuracy: 70.03%), lr: 1.0000e-03
        Epoch 11, train: (loss: 0.3529, accuracy: 77.12%), test: (loss: 0.4559, accuracy: 70.22%), lr: 1.0000e-03
        Epoch 12, train: (loss: 0.3357, accuracy: 78.31%), test: (loss: 0.4416, accuracy: 71.40%), lr: 1.0000e-03
        Epoch 13, train: (loss: 0.3209, accuracy: 79.06%), test: (loss: 0.5244, accuracy: 66.92%), lr: 1.0000e-03
        Epoch 14, train: (loss: 0.3085, accuracy: 79.87%), test: (loss: 0.4596, accuracy: 70.43%), lr: 1.0000e-03
        Epoch 15, train: (loss: 0.2962, accuracy: 80.70%), test: (loss: 0.4659, accuracy: 70.49%), lr: 1.0000e-03
        Epoch 16, train: (loss: 0.2848, accuracy: 81.71%), test: (loss: 0.4627, accuracy: 71.06%), lr: 1.0000e-03
        Epoch 17, train: (loss: 0.2724, accuracy: 82.24%), test: (loss: 0.5077, accuracy: 69.65%), lr: 1.0000e-03
        Epoch 18, train: (loss: 0.2624, accuracy: 82.91%), test: (loss: 0.4707, accuracy: 70.95%), lr: 1.0000e-03
        Epoch 19, train: (loss: 0.2547, accuracy: 83.53%), test: (loss: 0.4731, accuracy: 71.05%), lr: 1.0000e-03
        Epoch 20, train: (loss: 0.2405, accuracy: 84.40%), test: (loss: 0.4828, accuracy: 70.32%), lr: 1.0000e-03
        Epoch 21, train: (loss: 0.2335, accuracy: 84.88%), test: (loss: 0.4988, accuracy: 70.93%), lr: 1.0000e-03
        Epoch 22, train: (loss: 0.2264, accuracy: 85.47%), test: (loss: 0.4876, accuracy: 70.93%), lr: 1.0000e-03
        Epoch 23, train: (loss: 0.2192, accuracy: 85.95%), test: (loss: 0.4842, accuracy: 71.05%), lr: 1.0000e-03
        Epoch 24, train: (loss: 0.2118, accuracy: 86.45%), test: (loss: 0.4673, accuracy: 72.08%), lr: 1.0000e-03
        Epoch 25, train: (loss: 0.2033, accuracy: 86.90%), test: (loss: 0.5174, accuracy: 70.37%), lr: 1.0000e-03
        Epoch 26, train: (loss: 0.194, accuracy: 87.58%), test: (loss: 0.4774, accuracy: 72.20%), lr: 1.0000e-03
        Epoch 27, train: (loss: 0.1897, accuracy: 87.78%), test: (loss: 0.5632, accuracy: 70.09%), lr: 1.0000e-03
        Epoch 28, train: (loss: 0.1849, accuracy: 88.09%), test: (loss: 0.5294, accuracy: 71.06%), lr: 1.0000e-03
        Epoch 29, train: (loss: 0.186, accuracy: 88.06%), test: (loss: 0.5123, accuracy: 71.18%), lr: 1.0000e-03
        Epoch 30, train: (loss: 0.1755, accuracy: 88.82%), test: (loss: 0.5417, accuracy: 69.47%), lr: 1.0000e-03
    -> best accuracy, train: 88.82% (epoch 30), test: 72.20% (epoch 26)
    time taken:
        all: 100.00% (484.2 sec)
        getBatch: 1.81%, predict+loss: 31.79%, backward: 53.79%, step: 2.32%,
        metrics_base: 0.36%, metrics_moe: 1.10%, evaluate: 7.65%, 
        progressBar: 0.93%, other: 0.27%
    experts gates (tests):
        mean: [0. 0. 0. 0. 0.161 0. 0.376 0.16  0.23  0. 0. 0.072] (std: 0.118)
        std: [0. 0. 0. 0. 0.119 0. 0.303 0.125 0.179 0. 0. 0.116] (mean: 0.07)
        perClassPred: 
            [[0.   0.   0.   0.   0.   0.   0.   0.   0.   0.  ]
             [0.   0.   0.   0.   0.   0.   0.   0.   0.   0.  ]
             [0.   0.   0.   0.   0.   0.   0.   0.   0.   0.  ]
             [0.   0.   0.   0.   0.   0.   0.   0.   0.   0.  ]
             [0.09 0.03 0.25 0.15 0.26 0.11 0.22 0.43 0.02 0.1 ]
             [0.   0.   0.   0.   0.   0.   0.   0.   0.   0.  ]
             [0.5  0.88 0.14 0.22 0.17 0.1  0.05 0.21 0.68 0.85]
             [0.04 0.05 0.18 0.26 0.1  0.41 0.29 0.16 0.03 0.02]
             [0.04 0.04 0.38 0.35 0.46 0.37 0.44 0.2  0.01 0.02]
             [0.   0.   0.   0.   0.   0.   0.   0.   0.   0.  ]
             [0.   0.   0.   0.   0.   0.   0.   0.   0.   0.  ]
             [0.33 0.   0.05 0.01 0.01 0.   0.01 0.01 0.27 0.  ]]

---------------------------------------------------------------------------


here the results of the MOE (original loss from the paper) models to compare with

moe3 model 1 (gating:small, experts: 4 x medium)
    -> nb parameters: total(1_799_244), gating(27_748), experts(4 x 442_874)
    training:
        Epoch 1, train: (loss: 0.3936, accuracy: 40.47%), test: (loss: 0.3995, accuracy: 39.72%)
        Epoch 2, train: (loss: 0.286, accuracy: 57.91%), test: (loss: 0.2735, accuracy: 59.60%)
        Epoch 3, train: (loss: 0.2444, accuracy: 64.59%), test: (loss: 0.245, accuracy: 65.09%)
        Epoch 4, train: (loss: 0.2166, accuracy: 69.23%), test: (loss: 0.2149, accuracy: 69.01%)
        Epoch 5, train: (loss: 0.1959, accuracy: 72.36%), test: (loss: 0.2172, accuracy: 68.74%)
        Epoch 6, train: (loss: 0.1779, accuracy: 75.21%), test: (loss: 0.2427, accuracy: 65.87%)
        Epoch 7, train: (loss: 0.1628, accuracy: 77.45%), test: (loss: 0.2058, accuracy: 71.35%)
        Epoch 8, train: (loss: 0.1487, accuracy: 79.83%), test: (loss: 0.188, accuracy: 73.64%)
        Epoch 9, train: (loss: 0.1367, accuracy: 81.57%), test: (loss: 0.1906, accuracy: 73.43%)
        Epoch 10, train: (loss: 0.1244, accuracy: 83.29%), test: (loss: 0.1844, accuracy: 74.37%)
    -> best accuracy, train: 83.29% (epoch 10), test: 74.37% (epoch 10)
    time taken: same as: [moe2 model 2]
    experts gates (tests):
        mean: [0.007 0.328 0.    0.666] (std: 0.274)
        std: [0.011 0.404 0.    0.407] (mean: 0.205)
        perClassPred:
            [[0.03 0.   0.03 0.   0.   0.   0.   0.   0.   0.  ]
             [0.95 0.78 0.01 0.04 0.05 0.   0.02 0.02 0.99 0.56]
             [0.   0.   0.   0.   0.   0.   0.   0.   0.   0.  ]
             [0.02 0.22 0.96 0.96 0.95 1.   0.98 0.98 0.01 0.44]]



moe3 model 2 (gating:small, experts: 12 x small)
    -> nb parameters: total(422_244), gating(33_900), experts(12 x 32_362)
    training:
        Epoch 1, train: (loss: 0.3585, accuracy: 41.54%), test: (loss: 0.3646, accuracy: 41.77%)
        Epoch 2, train: (loss: 0.2949, accuracy: 54.56%), test: (loss: 0.3057, accuracy: 52.92%)
        Epoch 3, train: (loss: 0.265, accuracy: 59.81%), test: (loss: 0.3212, accuracy: 51.89%)
        Epoch 4, train: (loss: 0.247, accuracy: 62.90%), test: (loss: 0.2572, accuracy: 61.06%)
        Epoch 5, train: (loss: 0.2335, accuracy: 65.33%), test: (loss: 0.2423, accuracy: 63.65%)
        Epoch 6, train: (loss: 0.2201, accuracy: 67.67%), test: (loss: 0.2668, accuracy: 60.00%)
        Epoch 7, train: (loss: 0.2102, accuracy: 69.37%), test: (loss: 0.2282, accuracy: 65.73%)
        Epoch 8, train: (loss: 0.2037, accuracy: 70.31%), test: (loss: 0.2256, accuracy: 66.47%)
        Epoch 9, train: (loss: 0.1962, accuracy: 71.52%), test: (loss: 0.2137, accuracy: 68.69%)
        Epoch 10, train: (loss: 0.1902, accuracy: 72.66%), test: (loss: 0.2253, accuracy: 66.75%)
        Epoch 11, train: (loss: 0.1844, accuracy: 73.45%), test: (loss: 0.2226, accuracy: 67.61%)
        Epoch 12, train: (loss: 0.18, accuracy: 74.07%), test: (loss: 0.214, accuracy: 68.47%)
        Epoch 13, train: (loss: 0.1753, accuracy: 75.02%), test: (loss: 0.2198, accuracy: 68.09%)
        Epoch 14, train: (loss: 0.1699, accuracy: 75.81%), test: (loss: 0.2142, accuracy: 68.57%)
        Epoch 15, train: (loss: 0.169, accuracy: 75.95%), test: (loss: 0.2226, accuracy: 67.07%)
        Epoch 16, train: (loss: 0.1636, accuracy: 76.78%), test: (loss: 0.1889, accuracy: 72.88%)
        Epoch 17, train: (loss: 0.16, accuracy: 77.33%), test: (loss: 0.2002, accuracy: 71.03%)
        Epoch 18, train: (loss: 0.1563, accuracy: 77.89%), test: (loss: 0.2002, accuracy: 71.04%)
        Epoch 19, train: (loss: 0.1542, accuracy: 78.25%), test: (loss: 0.1936, accuracy: 71.77%)
        Epoch 20, train: (loss: 0.1499, accuracy: 79.01%), test: (loss: 0.227, accuracy: 67.56%)
        Epoch 21, train: (loss: 0.1485, accuracy: 79.11%), test: (loss: 0.1935, accuracy: 72.22%)
        Epoch 22, train: (loss: 0.1451, accuracy: 79.71%), test: (loss: 0.2107, accuracy: 69.36%)
        Epoch 23, train: (loss: 0.1416, accuracy: 80.35%), test: (loss: 0.1883, accuracy: 72.84%)
        Epoch 24, train: (loss: 0.1401, accuracy: 80.41%), test: (loss: 0.2122, accuracy: 69.22%)
        Epoch 25, train: (loss: 0.1375, accuracy: 80.98%), test: (loss: 0.2011, accuracy: 71.36%)
        Epoch 26, train: (loss: 0.1371, accuracy: 80.89%), test: (loss: 0.1892, accuracy: 73.15%)
        Epoch 27, train: (loss: 0.1328, accuracy: 81.54%), test: (loss: 0.1822, accuracy: 73.91%)
        Epoch 28, train: (loss: 0.131, accuracy: 81.93%), test: (loss: 0.1951, accuracy: 72.18%)
        Epoch 29, train: (loss: 0.1307, accuracy: 81.96%), test: (loss: 0.1871, accuracy: 73.40%)
        Epoch 30, train: (loss: 0.128, accuracy: 82.42%), test: (loss: 0.2088, accuracy: 70.08%)
    -> best accuracy, train: 82.42% (epoch 30), test: 73.91% (epoch 27)
    time taken:
        same as: [moe model 4]
    experts gates (tests):
        mean: [0.  0.  0.  0.239 0.  0.  0.  0.  0.  0.  0.  0.761] (std: 0.215)
        std: [0.  0.  0.  0.168 0.  0.  0.  0.  0.  0.  0.  0.168] (mean: 0.028)
        perClassPred: 
            [[0.   0.   0.   0.   0.   0.   0.   0.   0.   0.  ]
             [0.   0.   0.   0.   0.   0.   0.   0.   0.   0.  ]
             [0.   0.   0.   0.   0.   0.   0.   0.   0.   0.  ]
             [0.06 0.13 0.51 0.21 0.43 0.35 0.42 0.27 0.01 0.06]
             [0.   0.   0.   0.   0.   0.   0.   0.   0.   0.  ]
             [0.   0.   0.   0.   0.   0.   0.   0.   0.   0.  ]
             [0.   0.   0.   0.   0.   0.   0.   0.   0.   0.  ]
             [0.   0.   0.   0.   0.   0.   0.   0.   0.   0.  ]
             [0.   0.   0.   0.   0.   0.   0.   0.   0.   0.  ]
             [0.   0.   0.   0.   0.   0.   0.   0.   0.   0.  ]
             [0.   0.   0.   0.   0.   0.   0.   0.   0.   0.  ]
             [0.94 0.87 0.49 0.79 0.57 0.65 0.58 0.73 0.99 0.94]]
        

moe3 model 3 (gating:small, experts: 6 x small)
    -> nb parameters: total(223_458), gating(29_286), experts(6 x 32_362)
    training:
        Epoch 1, train: (loss: 0.3569, accuracy: 41.94%), test: (loss: 0.3154, accuracy: 51.32%)
        Epoch 2, train: (loss: 0.2971, accuracy: 54.33%), test: (loss: 0.2879, accuracy: 55.93%)
        Epoch 3, train: (loss: 0.2676, accuracy: 59.68%), test: (loss: 0.272, accuracy: 58.75%)
        Epoch 4, train: (loss: 0.2426, accuracy: 64.07%), test: (loss: 0.2579, accuracy: 61.21%)
        Epoch 5, train: (loss: 0.2268, accuracy: 66.44%), test: (loss: 0.2326, accuracy: 65.61%)
        Epoch 6, train: (loss: 0.2163, accuracy: 68.44%), test: (loss: 0.242, accuracy: 63.94%)
        Epoch 7, train: (loss: 0.2059, accuracy: 70.03%), test: (loss: 0.2179, accuracy: 68.02%)
        Epoch 8, train: (loss: 0.1994, accuracy: 71.04%), test: (loss: 0.2337, accuracy: 64.97%)
        Epoch 9, train: (loss: 0.191, accuracy: 72.56%), test: (loss: 0.2258, accuracy: 66.45%)
        Epoch 10, train: (loss: 0.186, accuracy: 73.28%), test: (loss: 0.2289, accuracy: 66.07%)
        Epoch 11, train: (loss: 0.1792, accuracy: 74.17%), test: (loss: 0.2139, accuracy: 68.24%)
        Epoch 12, train: (loss: 0.176, accuracy: 74.77%), test: (loss: 0.1948, accuracy: 71.67%)
        Epoch 13, train: (loss: 0.1716, accuracy: 75.61%), test: (loss: 0.2112, accuracy: 68.82%)
        Epoch 14, train: (loss: 0.1686, accuracy: 76.20%), test: (loss: 0.2004, accuracy: 70.78%)
        Epoch 15, train: (loss: 0.1635, accuracy: 76.70%), test: (loss: 0.1898, accuracy: 72.46%)
        Epoch 16, train: (loss: 0.1608, accuracy: 77.14%), test: (loss: 0.1905, accuracy: 72.48%)
        Epoch 17, train: (loss: 0.157, accuracy: 77.78%), test: (loss: 0.1984, accuracy: 71.43%)
        Epoch 18, train: (loss: 0.1564, accuracy: 77.88%), test: (loss: 0.1926, accuracy: 71.97%)
        Epoch 19, train: (loss: 0.1539, accuracy: 78.40%), test: (loss: 0.1754, accuracy: 74.67%)
        Epoch 20, train: (loss: 0.15, accuracy: 78.88%), test: (loss: 0.2033, accuracy: 70.28%)
        Epoch 21, train: (loss: 0.147, accuracy: 79.43%), test: (loss: 0.2117, accuracy: 69.47%)
        Epoch 22, train: (loss: 0.1465, accuracy: 79.44%), test: (loss: 0.1784, accuracy: 74.35%)
        Epoch 23, train: (loss: 0.1447, accuracy: 79.84%), test: (loss: 0.1815, accuracy: 73.79%)
        Epoch 24, train: (loss: 0.1416, accuracy: 80.34%), test: (loss: 0.1737, accuracy: 75.09%)
        Epoch 25, train: (loss: 0.1379, accuracy: 80.73%), test: (loss: 0.2008, accuracy: 71.21%)
        Epoch 26, train: (loss: 0.1376, accuracy: 80.82%), test: (loss: 0.1772, accuracy: 74.58%)
        Epoch 27, train: (loss: 0.1356, accuracy: 81.05%), test: (loss: 0.1836, accuracy: 73.81%)
        Epoch 28, train: (loss: 0.1346, accuracy: 81.30%), test: (loss: 0.1908, accuracy: 72.58%)
        Epoch 29, train: (loss: 0.1337, accuracy: 81.45%), test: (loss: 0.1911, accuracy: 72.70%)
        Epoch 30, train: (loss: 0.1321, accuracy: 81.44%), test: (loss: 0.1758, accuracy: 75.03%)
    -> best accuracy, train: 81.45% (epoch 29), test: 75.09% (epoch 24)
    time taken:
        same as: [moe model 2]
    experts gates (tests):
        mean: [0.  0.  0.  0.  0.094 0.906] (std: 0.332)
        std: [0.  0.  0.  0.  0.157 0.157] (mean: 0.052)
        perClassPred: 
            [[0.   0.   0.   0.   0.   0.   0.   0.   0.   0.  ]
             [0.   0.   0.   0.   0.   0.   0.   0.   0.   0.  ]
             [0.   0.   0.   0.   0.   0.   0.   0.   0.   0.  ]
             [0.   0.   0.   0.   0.   0.   0.   0.   0.   0.  ]
             [0.51 0.01 0.15 0.04 0.01 0.03 0.01 0.01 0.26 0.  ]
             [0.49 0.99 0.85 0.96 0.99 0.97 0.99 0.99 0.74 1.  ]]


moe3 model 4 (gating:small, experts: 6 x medium)
    -> nb parameters: total(2_686_530), gating(29_286), experts(6 x 442_874)
    training:
        Epoch 1, train: (loss: 0.3851, accuracy: 39.96%), test: (loss: 0.3092, accuracy: 52.51%), lr: 1.0000e-03
        Epoch 2, train: (loss: 0.2791, accuracy: 58.48%), test: (loss: 0.2825, accuracy: 57.81%), lr: 1.0000e-03
        Epoch 3, train: (loss: 0.2308, accuracy: 66.86%), test: (loss: 0.2188, accuracy: 68.04%), lr: 1.0000e-03
        Epoch 4, train: (loss: 0.2127, accuracy: 69.92%), test: (loss: 0.2135, accuracy: 69.01%), lr: 1.0000e-03
        Epoch 5, train: (loss: 0.1823, accuracy: 74.39%), test: (loss: 0.2093, accuracy: 70.37%), lr: 1.0000e-03
        Epoch 6, train: (loss: 0.1641, accuracy: 76.89%), test: (loss: 0.1712, accuracy: 75.78%), lr: 1.0000e-03
        Epoch 7, train: (loss: 0.1495, accuracy: 79.09%), test: (loss: 0.1739, accuracy: 75.17%), lr: 1.0000e-03
        Epoch 8, train: (loss: 0.1369, accuracy: 81.03%), test: (loss: 0.1779, accuracy: 74.78%), lr: 1.0000e-03
        Epoch 9, train: (loss: 0.125, accuracy: 82.70%), test: (loss: 0.1668, accuracy: 76.95%), lr: 1.0000e-03
        Epoch 10, train: (loss: 0.116, accuracy: 84.15%), test: (loss: 0.1818, accuracy: 74.47%), lr: 1.0000e-03
    -> best accuracy, train: 84.15% (epoch 10), test: 76.95% (epoch 9)
    time taken:
        all: 100.00% (167.0 sec)
        getBatch: 3.65%, predict+loss: 28.65%, backward: 55.53%, step: 2.03%, 
        metrics_base: 0.35%, metrics_moe: 1.06%, evaluate: 7.58%, 
        progressBar: 0.92%, other: 0.23%
    experts gates (tests):
        mean: [1. 0. 0. 0. 0. 0.] (std: 0.373)
        std: [0. 0. 0. 0. 0. 0.] (mean: 0.0)
        perClassPred: 
            [[1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]
             [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
             [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
             [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
             [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
             [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]






---------------------------------------------------------------------------
here the results of the MOE (logLikelihood loss version) models to compare with


moe4 model 1 (gating:small, experts: 6 x medium)
    -> nb parameters: total(2_686_530), gating(29_286), experts(6 x 442_874)
    training:
        Epoch 1, train: (loss: 1.541, accuracy: 44.79%), test: (loss: 1.217, accuracy: 57.78%), lr: 1.0000e-03
        Epoch 2, train: (loss: 1.051, accuracy: 63.56%), test: (loss: 1.166, accuracy: 61.14%), lr: 1.0000e-03
        Epoch 3, train: (loss: 0.8113, accuracy: 72.34%), test: (loss: 1.088, accuracy: 64.31%), lr: 1.0000e-03
        Epoch 4, train: (loss: 0.6835, accuracy: 76.60%), test: (loss: 0.7379, accuracy: 75.19%), lr: 1.0000e-03
        Epoch 5, train: (loss: 0.5931, accuracy: 79.74%), test: (loss: 0.7282, accuracy: 75.32%), lr: 1.0000e-03
        Epoch 6, train: (loss: 0.5099, accuracy: 82.79%), test: (loss: 0.7745, accuracy: 74.95%), lr: 1.0000e-03
        Epoch 7, train: (loss: 0.4358, accuracy: 85.15%), test: (loss: 0.6173, accuracy: 79.83%), lr: 1.0000e-03
        Epoch 8, train: (loss: 0.377, accuracy: 87.05%), test: (loss: 0.6361, accuracy: 79.19%), lr: 1.0000e-03
        Epoch 9, train: (loss: 0.3158, accuracy: 89.27%), test: (loss: 0.7984, accuracy: 75.38%), lr: 1.0000e-03
        Epoch 10, train: (loss: 0.2677, accuracy: 90.81%), test: (loss: 0.7455, accuracy: 78.47%), lr: 1.0000e-03
    -> best accuracy, train: 90.81% (epoch 10), test: 79.83% (epoch 7)
    time taken:
        all: 100.00% (171 sec)
        getBatch: 3.87%, predict+loss: 28.73%, backward: 55.55%, step: 2.02%, 
        metrics_base: 0.34%, metrics_moe: 1.02%, evaluate: 7.37%, 
        progressBar: 0.87%, other: 0.22%
    experts gates (tests):
        mean: [0.996 0. 0. 0. 0. 0.004] (std: 0.371)
        std: [0.002 0. 0. 0. 0. 0.002] (mean: 0.001)
        perClassPred: 
            [[1.   1.   1.   0.99 1.   0.99 1.   0.99 1.   0.99]
             [0.   0.   0.   0.   0.   0.   0.   0.   0.   0.  ]
             [0.   0.   0.   0.   0.   0.   0.   0.   0.   0.  ]
             [0.   0.   0.   0.   0.   0.   0.   0.   0.   0.  ]
             [0.   0.   0.   0.   0.   0.   0.   0.   0.   0.  ]
             [0.   0.   0.   0.01 0.   0.   0.   0.   0.   0.01]]

moe4 model 2 (gating:small, experts: 4 x medium)
    -> nb parameters: total(1_799_244), gating(27_748), experts(4 x 442_874)
    training:
        Epoch 1, train: (loss: 1.577, accuracy: 43.66%), test: (loss: 1.615, accuracy: 43.73%), lr: 1.0000e-03
        Epoch 2, train: (loss: 1.122, accuracy: 60.82%), test: (loss: 0.973, accuracy: 66.36%), lr: 1.0000e-03
        Epoch 3, train: (loss: 0.9101, accuracy: 68.20%), test: (loss: 1.154, accuracy: 60.98%), lr: 1.0000e-03
        Epoch 4, train: (loss: 0.7796, accuracy: 73.05%), test: (loss: 0.8674, accuracy: 71.20%), lr: 1.0000e-03
        Epoch 5, train: (loss: 0.6938, accuracy: 76.20%), test: (loss: 0.8122, accuracy: 72.28%), lr: 1.0000e-03
        Epoch 6, train: (loss: 0.6168, accuracy: 78.67%), test: (loss: 0.7997, accuracy: 73.66%), lr: 1.0000e-03
        Epoch 7, train: (loss: 0.54, accuracy: 81.32%), test: (loss: 0.772, accuracy: 74.44%), lr: 1.0000e-03
        Epoch 8, train: (loss: 0.4962, accuracy: 82.72%), test: (loss: 0.7327, accuracy: 75.89%), lr: 1.0000e-03
        Epoch 9, train: (loss: 0.4349, accuracy: 84.94%), test: (loss: 0.8039, accuracy: 74.97%), lr: 1.0000e-03
        Epoch 10, train: (loss: 0.3934, accuracy: 86.38%), test: (loss: 0.6834, accuracy: 78.26%), lr: 1.0000e-03
    -> best accuracy, train: 86.38% (epoch 10), test: 78.26% (epoch 10)
    time taken:
        all: 100.00% (128.7 sec)
        getBatch: 4.98%, predict+loss: 27.77%, backward: 54.10%, step: 2.16%,
        metrics_base: 0.46%, metrics_moe: 1.40%, evaluate: 7.65%,
        progressBar: 1.23%, other: 0.26%
    experts gates (tests):
        mean: [0.116 0.022 0.02  0.842] (std: 0.344)
        std: [0.172 0.038 0.029 0.204] (mean: 0.111)
        perClassPred: 
            [[0.06 0.01 0.63 0.1  0.18 0.13 0.12 0.09 0.02 0.02]
             [0.   0.   0.01 0.03 0.01 0.01 0.13 0.   0.   0.  ]
             [0.01 0.   0.11 0.02 0.03 0.03 0.02 0.01 0.   0.  ]
             [0.92 0.98 0.25 0.86 0.78 0.83 0.73 0.9  0.97 0.97]]

moe4 model 3 (gating:small, experts: 6 x small)
    -> nb parameters: total(223_458), gating(29_286), experts(6 x 32_362)
    training:
        Epoch 1, train: (loss: 1.546, accuracy: 44.32%), test: (loss: 1.35, accuracy: 51.20%), lr: 1.0000e-03
        Epoch 2, train: (loss: 1.206, accuracy: 57.16%), test: (loss: 1.173, accuracy: 59.08%), lr: 1.0000e-03
        Epoch 3, train: (loss: 1.07, accuracy: 62.09%), test: (loss: 1.266, accuracy: 56.61%), lr: 1.0000e-03
        Epoch 4, train: (loss: 0.9825, accuracy: 65.50%), test: (loss: 1.009, accuracy: 64.73%), lr: 1.0000e-03
        Epoch 5, train: (loss: 0.9126, accuracy: 67.98%), test: (loss: 1.175, accuracy: 60.43%), lr: 1.0000e-03
        Epoch 6, train: (loss: 0.8551, accuracy: 70.06%), test: (loss: 0.9633, accuracy: 66.60%), lr: 1.0000e-03
        Epoch 7, train: (loss: 0.8154, accuracy: 71.41%), test: (loss: 0.9211, accuracy: 67.53%), lr: 1.0000e-03
        Epoch 8, train: (loss: 0.7711, accuracy: 73.04%), test: (loss: 0.9429, accuracy: 66.77%), lr: 1.0000e-03
        Epoch 9, train: (loss: 0.7386, accuracy: 74.11%), test: (loss: 1.015, accuracy: 65.20%), lr: 1.0000e-03
        Epoch 10, train: (loss: 0.7046, accuracy: 75.35%), test: (loss: 0.9469, accuracy: 67.26%), lr: 1.0000e-03
        Epoch 11, train: (loss: 0.6824, accuracy: 76.25%), test: (loss: 0.9092, accuracy: 68.00%), lr: 1.0000e-03
        Epoch 12, train: (loss: 0.6495, accuracy: 77.10%), test: (loss: 0.8397, accuracy: 70.93%), lr: 1.0000e-03
        Epoch 13, train: (loss: 0.6284, accuracy: 77.90%), test: (loss: 0.8367, accuracy: 71.19%), lr: 1.0000e-03
        Epoch 14, train: (loss: 0.6047, accuracy: 78.41%), test: (loss: 0.8941, accuracy: 69.40%), lr: 1.0000e-03
        Epoch 15, train: (loss: 0.5834, accuracy: 79.68%), test: (loss: 1.002, accuracy: 65.71%), lr: 1.0000e-03
        Epoch 16, train: (loss: 0.5681, accuracy: 80.16%), test: (loss: 0.828, accuracy: 71.03%), lr: 1.0000e-03
        Epoch 17, train: (loss: 0.5492, accuracy: 80.41%), test: (loss: 0.7816, accuracy: 73.29%), lr: 1.0000e-03
        Epoch 18, train: (loss: 0.5243, accuracy: 81.40%), test: (loss: 0.7979, accuracy: 72.86%), lr: 1.0000e-03
        Epoch 19, train: (loss: 0.5083, accuracy: 81.89%), test: (loss: 0.8401, accuracy: 71.83%), lr: 1.0000e-03
        Epoch 20, train: (loss: 0.4895, accuracy: 82.92%), test: (loss: 0.8006, accuracy: 72.51%), lr: 1.0000e-03
        Epoch 21, train: (loss: 0.481, accuracy: 82.84%), test: (loss: 0.8224, accuracy: 72.47%), lr: 1.0000e-03
        Epoch 22, train: (loss: 0.4639, accuracy: 83.52%), test: (loss: 0.8181, accuracy: 72.31%), lr: 1.0000e-03
        Epoch 23, train: (loss: 0.4498, accuracy: 84.20%), test: (loss: 0.8836, accuracy: 70.52%), lr: 1.0000e-03
        Epoch 24, train: (loss: 0.4375, accuracy: 84.33%), test: (loss: 0.8541, accuracy: 72.23%), lr: 1.0000e-03
        Epoch 25, train: (loss: 0.421, accuracy: 84.81%), test: (loss: 0.8718, accuracy: 71.07%), lr: 1.0000e-03
        Epoch 26, train: (loss: 0.411, accuracy: 85.23%), test: (loss: 0.9318, accuracy: 70.39%), lr: 1.0000e-03
        Epoch 27, train: (loss: 0.4007, accuracy: 85.64%), test: (loss: 0.8579, accuracy: 72.31%), lr: 1.0000e-03
        Epoch 28, train: (loss: 0.3919, accuracy: 85.88%), test: (loss: 0.8379, accuracy: 73.30%), lr: 1.0000e-03
        Epoch 29, train: (loss: 0.378, accuracy: 86.48%), test: (loss: 0.8656, accuracy: 72.19%), lr: 1.0000e-03
        Epoch 30, train: (loss: 0.3667, accuracy: 86.83%), test: (loss: 0.9377, accuracy: 70.06%), lr: 1.0000e-03
    -> best accuracy, train: 86.83% (epoch 30), test: 73.30% (epoch 28)
    time taken:
        all: 100.00% (278.5 sec)
        getBatch: 2.89%, predict+loss: 30.73%, backward: 51.97%, step: 2.73%,
        metrics_base: 0.62%, metrics_moe: 1.91%, evaluate: 7.87%,
        progressBar: 0.94%, other: 0.34%
    experts gates (tests):
        mean: [0.021 0.03  0.144 0.153 0.456 0.197] (std: 0.145)
        std: [0.065 0.063 0.164 0.149 0.319 0.192] (mean: 0.159)
        perClassPred: 
            [[0.   0.   0.01 0.01 0.22 0.   0.01 0.   0.   0.  ]
             [0.01 0.   0.22 0.01 0.01 0.01 0.01 0.   0.   0.  ]
             [0.58 0.01 0.27 0.06 0.16 0.05 0.14 0.11 0.05 0.02]
             [0.2  0.01 0.25 0.13 0.1  0.15 0.05 0.06 0.54 0.01]
             [0.19 0.97 0.15 0.29 0.41 0.26 0.54 0.78 0.06 0.96]
             [0.02 0.01 0.11 0.5  0.1  0.53 0.25 0.05 0.36 0.01]]

moe4 model 4 (gating:small, experts: 12 x small)
    -> nb parameters: total(422_244), gating(33_900), experts(12 x 32_362)
    training:
        Epoch 1, train: (loss: 1.54, accuracy: 44.43%), test: (loss: 1.316, accuracy: 53.27%), lr: 1.0000e-03
        Epoch 2, train: (loss: 1.187, accuracy: 58.22%), test: (loss: 1.142, accuracy: 60.04%), lr: 1.0000e-03
        Epoch 3, train: (loss: 1.046, accuracy: 63.13%), test: (loss: 1.146, accuracy: 59.20%), lr: 1.0000e-03
        Epoch 4, train: (loss: 0.9484, accuracy: 66.89%), test: (loss: 1.124, accuracy: 58.55%), lr: 1.0000e-03
        Epoch 5, train: (loss: 0.8821, accuracy: 69.33%), test: (loss: 0.9312, accuracy: 68.17%), lr: 1.0000e-03
        Epoch 6, train: (loss: 0.8316, accuracy: 71.06%), test: (loss: 1.013, accuracy: 64.17%), lr: 1.0000e-03
        Epoch 7, train: (loss: 0.779, accuracy: 72.59%), test: (loss: 0.8677, accuracy: 69.89%), lr: 1.0000e-03
        Epoch 8, train: (loss: 0.7403, accuracy: 74.07%), test: (loss: 1.018, accuracy: 64.21%), lr: 1.0000e-03
        Epoch 9, train: (loss: 0.706, accuracy: 75.24%), test: (loss: 1.02, accuracy: 64.73%), lr: 1.0000e-03
        Epoch 10, train: (loss: 0.6762, accuracy: 76.49%), test: (loss: 0.8277, accuracy: 71.43%), lr: 1.0000e-03
        Epoch 11, train: (loss: 0.6552, accuracy: 76.91%), test: (loss: 0.8241, accuracy: 71.72%), lr: 1.0000e-03
        Epoch 12, train: (loss: 0.6192, accuracy: 78.21%), test: (loss: 0.9756, accuracy: 67.53%), lr: 1.0000e-03
        Epoch 13, train: (loss: 0.5882, accuracy: 79.20%), test: (loss: 0.8149, accuracy: 71.79%), lr: 1.0000e-03
        Epoch 14, train: (loss: 0.5716, accuracy: 79.90%), test: (loss: 0.8032, accuracy: 72.52%), lr: 1.0000e-03
        Epoch 15, train: (loss: 0.5492, accuracy: 80.66%), test: (loss: 0.7626, accuracy: 73.63%), lr: 1.0000e-03
        Epoch 16, train: (loss: 0.5302, accuracy: 81.39%), test: (loss: 0.7617, accuracy: 74.29%), lr: 1.0000e-03
        Epoch 17, train: (loss: 0.5092, accuracy: 81.92%), test: (loss: 0.8718, accuracy: 70.72%), lr: 1.0000e-03
        Epoch 18, train: (loss: 0.4913, accuracy: 82.63%), test: (loss: 0.8371, accuracy: 72.52%), lr: 1.0000e-03
        Epoch 19, train: (loss: 0.4752, accuracy: 83.12%), test: (loss: 0.782, accuracy: 73.28%), lr: 1.0000e-03
        Epoch 20, train: (loss: 0.4608, accuracy: 83.43%), test: (loss: 0.7767, accuracy: 74.07%), lr: 1.0000e-03
        Epoch 21, train: (loss: 0.4419, accuracy: 84.11%), test: (loss: 0.7675, accuracy: 74.73%), lr: 1.0000e-03
        Epoch 22, train: (loss: 0.4247, accuracy: 84.84%), test: (loss: 0.8322, accuracy: 72.24%), lr: 1.0000e-03
        Epoch 23, train: (loss: 0.4173, accuracy: 85.02%), test: (loss: 0.7932, accuracy: 73.92%), lr: 1.0000e-03
        Epoch 24, train: (loss: 0.4066, accuracy: 85.49%), test: (loss: 0.8696, accuracy: 71.60%), lr: 1.0000e-03
        Epoch 25, train: (loss: 0.3841, accuracy: 86.17%), test: (loss: 0.8024, accuracy: 73.72%), lr: 1.0000e-03
        Epoch 26, train: (loss: 0.3797, accuracy: 86.34%), test: (loss: 0.7774, accuracy: 74.87%), lr: 1.0000e-03
        Epoch 27, train: (loss: 0.3684, accuracy: 86.82%), test: (loss: 0.8927, accuracy: 71.83%), lr: 1.0000e-03
        Epoch 28, train: (loss: 0.3516, accuracy: 87.36%), test: (loss: 0.8807, accuracy: 72.32%), lr: 1.0000e-03
        Epoch 29, train: (loss: 0.3419, accuracy: 87.69%), test: (loss: 0.8582, accuracy: 73.42%), lr: 1.0000e-03
        Epoch 30, train: (loss: 0.3337, accuracy: 88.05%), test: (loss: 0.8364, accuracy: 73.21%), lr: 1.0000e-03
    -> best accuracy, train: 88.05% (epoch 30), test: 74.87% (epoch 26)
    time taken:
        all: 100.00% (482.5 sec)
        getBatch: 1.76%, predict+loss: 31.69%, backward: 53.92%, step: 2.51%,
        metrics_base: 0.38%, metrics_moe: 1.13%, evaluate: 7.40%, 
        progressBar: 0.94%, other: 0.27%
    experts gates (tests):
        mean: [0. 0.339 0.001 0.049 0. 0. 0.34  0. 0.067 0.2   0. 0.003] (std: 0.127)
        std: [0. 0.194 0.001 0.047 0. 0. 0.367 0. 0.124 0.198 0. 0.008] (mean: 0.078)
        perClassPred:
            [[0.   0.   0.   0.   0.   0.   0.   0.   0.   0.  ]
             [0.19 0.12 0.5  0.56 0.37 0.52 0.32 0.61 0.13 0.06]
             [0.   0.   0.   0.   0.   0.   0.   0.   0.   0.  ]
             [0.01 0.01 0.14 0.07 0.09 0.09 0.07 0.02 0.   0.  ]
             [0.   0.   0.   0.   0.   0.   0.   0.   0.   0.  ]
             [0.   0.   0.   0.   0.   0.   0.   0.   0.   0.  ]
             [0.34 0.86 0.04 0.03 0.09 0.01 0.01 0.23 0.84 0.93]
             [0.   0.   0.   0.   0.   0.   0.   0.   0.   0.  ]
             [0.42 0.   0.12 0.03 0.01 0.   0.01 0.   0.02 0.  ]
             [0.01 0.01 0.19 0.31 0.43 0.38 0.59 0.14 0.01 0.01]
             [0.   0.   0.   0.   0.   0.   0.   0.   0.   0.  ]
             [0.03 0.   0.   0.   0.   0.   0.   0.   0.   0.  ]]


resume:
    base model 2 (small)
        - nb parameters: 32_362
        - best accuracy, train: 80.38% (epoch 30), test: 74.80% (epoch 27)
        - time taken: 52.5 sec
    base model 1 (medium)
        - nb parameters: 442_874
        - best accuracy, train: 90.08 (epoch 10), test: 78.76% (epoch 8)
        - time taken: 35.8 sec
    base model 3 (large)
        - nb parameters: 1_928_138
        - best accuracy, train: 88.46% (epoch 10), test: 80.38% (epoch 10)
        - time taken: 77.0 sec
---------------------------------------------------------------------------
    moe model 1 (gating:small, experts: 12 x small)
        - nb parameters: total(422_244), gating(33_900), experts(12 x 32_362)
        - best accuracy, train: 80.93% (epoch 30), test: 75.27% (epoch 27)
        - time taken: 459.0 sec
        - experts gates:
            mean: [0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] (std: 0.276)
            std: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] (mean: 0.0)
    moe model 2 (gating:small, experts: 6 x small)
        - nb parameters: total(223_458), gating(29_286), experts(6 x 32_362)
        - best accuracy, train: 80.78% (epoch 30), test: 75.59% (epoch 27)
        - time taken: 260.7 sec
        - experts gates:
            mean: [0. 0. 0. 0. 0. 1.] (std: 0.373)
            std: [0. 0. 0. 0. 0. 0.] (mean: 0.0)
    moe model 3 (gating:medium, experts: 6 x small)
        - nb parameters: total(620_658), gating(426_486), experts(6 x 32_362)
        - best accuracy, train: 84.15% (epoch 30), test: 74.57% (epoch 26)
        - time taken: 422.6 sec
    moe model 4 (gating:small, experts: 4 x medium)
        - nb parameters: total(1_799_244), gating(27_748), experts(4 x 442_874)
        - best accuracy, train: 91.17% (epoch 10), test: 79.92% (epoch 9)
        - time taken: 117.9 sec
        - experts gates:
            mean: [1. 0. 0. 0.] (std: 0.433)
            std: [0.001 0.    0.    0.   ] (mean: 0.0)
    moe model 5 (gating:medium, experts: 4 x medium)
        - nb parameters: total(2_189_788), gating(418_292), experts(4 x 442_874)
        - best accuracy, train: 89.89% (epoch 10), test: 79.33% (epoch 10)
        - time taken: 133.0 sec
        - experts gates:
            mean: [0. 0. 0. 1.] (std: 0.433)
            std: [0. 0. 0. 0.] (mean: 0.0)
    moe model 6 (gating:small, experts: 4 x large)
        - nb parameters: total(7_740_300), gating(27_748), experts(4 x 1_928_138)
        - best accuracy, train: 84.49% (epoch 10), test: 77.88% (epoch 9)
        - time taken: 305.0 sec
    moe model 7 (gating:medium, experts: 4 x large)
        - nb parameters: total(8_130_844), gating(418_292), experts(4 x 1_928_138)
        - best accuracy, train: 89.19% (epoch 10), test: 79.83% (epoch 9)
        - time taken: 319.1 sec
---------------------------------------------------------------------------
    moe2 model 1 (gating:small, experts: 6 x small)
        - nb parameters: total(223_458), gating(29_286), experts(6 x 32_362)
        - best accuracy, train: 89.80% (epoch 30), test: 71.26% (epoch 21)
        - time taken: 265.3 sec
        - experts gates:
            mean: [0.237 0.142 0.176 0.201 0.086 0.159] (std: 0.047)
            std: [0.154 0.11  0.188 0.245 0.093 0.083] (mean: 0.146)
    moe2 model 2 (gating:small, experts: 4 x medium)
        - nb parameters: total(1_799_244), gating(27_748), experts(4 x 442_874)
        - best accuracy, train: 90.21% (epoch 10), test: 77.60% (epoch 9)
        - time taken: 123.5 sec
        - experts gates (tests):
            mean: [0.244 0.274 0.169 0.314] (std: 0.053)
            std: [0.09  0.123 0.13  0.134] (mean: 0.119)
    moe2 model 3 (gating:small, experts: 12 x small)
        - nb parameters: total(422_244), gating(33_900), experts(12 x 32_362)
        - best accuracy, train: 88.82% (epoch 30), test: 72.20% (epoch 26)
        - time taken: 484.2 sec
        - experts gates (tests):
            mean: [0. 0. 0. 0. 0.161 0. 0.376 0.16  0.23  0. 0. 0.072] (std: 0.118)
            std: [0. 0. 0. 0. 0.119 0. 0.303 0.125 0.179 0. 0. 0.116] (mean: 0.07)
---------------------------------------------------------------------------
    moe3 model 1 (gating:small, experts: 4 x medium)
        - nb parameters: total(1_799_244), gating(27_748), experts(4 x 442_874)
        - best accuracy, train: 83.29% (epoch 10), test: 74.37% (epoch 10)
        - time taken: 123.5 sec
        - experts gates (tests):
            mean: [0.007 0.328 0.    0.666] (std: 0.274)
            std: [0.011 0.404 0.    0.407] (mean: 0.205)
    moe3 model 2 (gating:small, experts: 12 x small)
        - nb parameters: total(422_244), gating(33_900), experts(12 x 32_362)
        - best accuracy, train: 82.42% (epoch 30), test: 73.91% (epoch 27)
        - time taken: 459.0 sec
        - experts gates (tests):
            mean: [0. 0. 0. 0.239 0. 0. 0. 0. 0. 0. 0. 0.761] (std: 0.215)
            std: [0. 0. 0. 0.168 0. 0. 0. 0. 0. 0. 0. 0.168] (mean: 0.028)
    moe3 model 3 (gating:small, experts: 6 x small)
        - nb parameters: total(223_458), gating(29_286), experts(6 x 32_362)
        - best accuracy, train: 81.45% (epoch 29), test: 75.09% (epoch 24)
        - time taken: 260.7 sec
        - experts gates (tests):
            mean: [0.  0.  0.  0.  0.094 0.906] (std: 0.332)
            std: [0.  0.  0.  0.  0.157 0.157] (mean: 0.052)
    moe3 model 4 (gating:small, experts: 6 x medium)
        - nb parameters: total(2_686_530), gating(29_286), experts(6 x 442_874)
        - best accuracy, train: 84.15% (epoch 10), test: 76.95% (epoch 9)
        - time taken: 167.0 sec
        - experts gates (tests):
            mean: [1. 0. 0. 0. 0. 0.] (std: 0.373)
            std: [0. 0. 0. 0. 0. 0.] (mean: 0.0)
---------------------------------------------------------------------------
    moe4 model 1 (gating:small, experts: 6 x medium)
        - nb parameters: total(2_686_530), gating(29_286), experts(6 x 442_874)
        - best accuracy, train: 90.81% (epoch 10), test: 79.83% (epoch 7)
        - time taken: 171 sec
        - experts gates (tests):
            - mean: [0.996 0. 0. 0. 0. 0.004] (std: 0.371)
            - std: [0.002 0. 0. 0. 0. 0.002] (mean: 0.001)
    moe4 model 2 (gating:small, experts: 4 x medium)
        - nb parameters: total(1_799_244), gating(27_748), experts(4 x 442_874)
        - best accuracy, train: 86.38% (epoch 10), test: 78.26% (epoch 10)
        - time taken: 128.7 sec
        - experts gates (tests):
            mean: [0.116 0.022 0.02  0.842] (std: 0.344)
            std: [0.172 0.038 0.029 0.204] (mean: 0.111)
    moe4 model 3 (gating:small, experts: 6 x small)
        - nb parameters: total(223_458), gating(29_286), experts(6 x 32_362)
        - best accuracy, train: 86.83% (epoch 30), test: 73.30% (epoch 28)
        - time taken: 278.5 sec
        -experts gates (tests):
            mean: [0.021 0.03  0.144 0.153 0.456 0.197] (std: 0.145)
            std: [0.065 0.063 0.164 0.149 0.319 0.192] (mean: 0.159)
    moe4 model 4 (gating:small, experts: 12 x small)
        - nb parameters: total(422_244), gating(33_900), experts(12 x 32_362)
        - best accuracy, train: 88.05% (epoch 30), test: 74.87% (epoch 26)
        - time taken: 482.5 sec
        - experts gates (tests):
            mean: [0. 0.339 0.001 0.049 0. 0. 0.34  0. 0.067 0.2   0. 0.003] (std: 0.127)
            std: [0. 0.194 0.001 0.047 0. 0. 0.367 0. 0.124 0.198 0. 0.008] (mean: 0.078)





table:

------------------------------------------------------------------------------------------------------------------
| config            | parameters | nbEpoches | trainAccuracy | testAccuracy | trainTime | GVofM | GMofV | nbUsed |
------------------------------------------------------------------------------------------------------------------
| base models, no experts                                                                                        |
------------------------------------------------------------------------------------------------------------------
| small             |     32'362 |        30 |         80.3% |        74.8% |    52 sec |     - |     - |      - |
| medium            |    442'874 |        10 |         90.0% |        78.7% |    35 sec |     - |     - |      - |
| large             |  1'928'138 |        10 |         88.4% |        80.3% |    77 sec |     - |     - |      - |
------------------------------------------------------------------------------------------------------------------
| MoE from (Jacobs et al., 1991), using modified loss with cross entropy (see ...)                               |
------------------------------------------------------------------------------------------------------------------
| small + 6 small   |    223'458 |        30 |         80.7% |        75.5% |   260 sec | 0.373 |   0.0 |      1 |
| small + 12 small  |    422'244 |        30 |         80.9% |        75.2% |   459 sec | 0.276 |   0.0 |      1 |
| small + 4 medium  |  1'799'244 |        10 |         91.1% |        79.9% |   117 sec | 0.433 |   0.0 |      1 |
| small + 4 large   |  7'740'300 |        10 |         84.4% |        77.8% |   305 sec |     - |     - |      1 |
| medium + 6 small  |    620'658 |        30 |         84.1% |        74.5% |   422 sec |     - |     - |      1 |
| medium + 4 medium |  2'189'788 |        10 |         89.8% |        79.3% |   133 sec | 0.433 |   0.0 |      1 |
| medium + 4 large  |  8'130'844 |        10 |         89.1% |        79.8% |   319 sec |     - |     - |      1 |
------------------------------------------------------------------------------------------------------------------
| MoE from (Jacobs et al., 1991), using modified loss with cross entropy + simple load balancing                 |
------------------------------------------------------------------------------------------------------------------
| small + 6 small   |    223'458 |        30 |         89.8% |        71.2% |   265 sec | 0.047 | 0.146 |      6 |
| small + 12 small  |    422'244 |        30 |         88.8% |        72.2% |   484 sec | 0.118 | 0.070 |      5 |
| small + 4 medium  |  1'799'244 |        10 |         90.2% |        77.6% |   123 sec | 0.053 | 0.119 |      4 |
------------------------------------------------------------------------------------------------------------------
| MoE from (Jacobs et al., 1991), using the original loss from the paper (so, no load balancing)                 |
------------------------------------------------------------------------------------------------------------------
| small + 6 small   |    223'458 |        29 |         81.4% |        75.0% |   260 sec | 0.332 | 0.052 |      2 |
| small + 12 small  |    422'244 |        30 |         82.4% |        73.9% |   459 sec | 0.215 | 0.028 |      2 |
| small + 4 medium  |  1'799'244 |        10 |         83.2% |        74.3% |   123 sec | 0.274 | 0.205 |      2 |
| small + 6 medium  |  2'686'530 |        10 |         84.1% |        76.9% |   167 sec | 0.373 |   0.0 |      1 |
------------------------------------------------------------------------------------------------------------------
| MoE from (Jacobs et al., 1991), using with the simple cross entropy loss (see ...) (no load balancing)         |
------------------------------------------------------------------------------------------------------------------
| small + 6 small   |  223'458   |        30 |         86.8% |        73.3% |   278 sec | 0.145 | 0.159 |  4 ~ 6 |
| small + 12 small  |  422'244   |        30 |         88.0% |        74.8% |   482 sec | 0.127 | 0.078 |  4 ~ 5 |
| small + 4 medium  |  1'799'244 |        10 |         86.3% |        78.2% |   128 sec | 0.344 | 0.111 |  2 ~ 4 |
| small + 6 medium  |  2'686'530 |        10 |         90.8% |        79.8% |   171 sec | 0.371 | 0.001 |      1 |
------------------------------------------------------------------------------------------------------------------


--------------------------------------------------------------------------------------------------------
| loss version              | trainAccuracy | testAccuracy | rank | trainTime | GVofM | GMofV | nbUsed |
--------------------------------------------------------------------------------------------------------
|      small + 6 small, 223'458 parameters, 30 epoches                                                 |
--------------------------------------------------------------------------------------------------------
| base 1 small (32'362 p)   |         80.3% |        74.8% |    3 |    52 sec |     - |     - |      - |
| original + CE             |         80.7% |        75.5% |    1 |   260 sec | 0.373 |   0.0 |      1 |
| original + CE + balance   |         89.8% |        71.2% |    5 |   265 sec | 0.047 | 0.146 |      6 |
| original (MSE)            |         81.4% |        75.0% |    2 |   260 sec | 0.332 | 0.052 |      2 |
| cross entropy             |         86.8% |        73.3% |    4 |   278 sec | 0.145 | 0.159 |  4 ~ 6 |
--------------------------------------------------------------------------------------------------------
|      small + 12 small, 422'244 parameters, 30 epoches                                                |
--------------------------------------------------------------------------------------------------------
| base 1 small (32'362 p)   |         80.3% |        74.8% |    2 |    52 sec |     - |     - |      - |
| original + CE             |         80.9% |        75.2% |    1 |   459 sec | 0.276 |   0.0 |      1 |
| original + CE + balance   |         88.8% |        72.2% |    5 |   484 sec | 0.118 | 0.070 |      5 |
| original (MSE)            |         82.4% |        73.9% |    4 |   459 sec | 0.215 | 0.028 |      2 |
| cross entropy             |         88.0% |        74.8% |    3 |   482 sec | 0.127 | 0.078 |  4 ~ 5 |
--------------------------------------------------------------------------------------------------------
|      small + 4 medium, 1'799'244 parameters, 10 epoches                                              |
--------------------------------------------------------------------------------------------------------
| base 1 medium (442'874 p) |         90.0% |        78.7% |    2 |    35 sec |     - |     - |      - |
| original + CE             |         91.1% |        79.9% |    1 |   117 sec | 0.433 |   0.0 |      1 |
| original + CE + balance   |         90.2% |        77.6% |    4 |   123 sec | 0.053 | 0.119 |      4 |
| original (MSE)            |         83.2% |        74.3% |    5 |   123 sec | 0.274 | 0.205 |      2 |
| cross entropy             |         86.3% |        78.2% |    3 |   128 sec | 0.344 | 0.111 |  2 ~ 4 |
--------------------------------------------------------------------------------------------------------


legend: 
GVofM: standard deviation of mean gate activation of experts overall
    ie. ~ how much a few expert is doing most of the work, so for the same number of experts, lower value is better 
    so a high value means that there is a single expert being used
GMofV: mean of standard deviation of gate activation of experts accros the differant classes
    ie. ~ how much the experts are working on only some classes and not always all classes, so higher is better
    so a value of 0.0 mean that activated experts always works on all classes
nbUsed (a ~ b): the number of experts used (single number means a = b)
    a are the number of experts that are slighty used a lot
    b are the number of experts that are slighty used or more


conclusions:
    Using experts that are too small leads to bad results, even when with the amount of experts where
        the total number of parameters of the MoE equals the medium model
    In this situation we can see that using the large base model don't give much better results than 
        the base medium model that is sinificantly faster to train.
    Using the large configuration for experts or the medium or larger configurations for the gating network
        didn't lead to better results either, and again it slowed a lot the training.
    With the implementation of the loss (see ...) from the paper (...), 
        the MoE models performed the same as the experts base configuration. 
        We can see that the gating tends to always select the same single expert, 
            so the MoE acts like it was a single Expert, while continuing to train all the other experts.
        With that issue it is normal that increasing the number of experts din't lead to any improvements.
    In order to try solving this problem i tried a simple fix, 
        I modified the original loss by adding a punishment when expertts where far from being evenly used acros a batch.
        This fixed the problem of the MoE becoming a single expert model, 
            but it lead to worst testing performances and more overfining on the small experts.
    When i used the original loss from the paper (ie. using the norm insted of cross entropy), 
        it slighty improved the routing of the experts, some of the training resulted in 2 experts being used at the end.
        But it seems that the training is less good and stable, 
        because for the model (small + 6 medium) it finished with a single expert, 
        and many another training of this model never predicted one of the classes.
        About the test performances, this is either worst or the same as with the CE
    when using the log logLikelihood loss, it resulted 
        in automatic load balancing betwin the experts 
        and some good performances compared to the other methodes.



___ model ___ (gating:___, experts: ___ x ___)
    -> nb parameters: total(___), gating(___), experts(___ x ___)
    training:
        ___
    -> best accuracy, train: ___% (epoch ___), test: ___% (epoch ___)
    time taken:
        all: 100.00% (___ sec)
        ___
    experts gates (tests):
        ___
    